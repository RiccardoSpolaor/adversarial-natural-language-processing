{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "\n",
    "SEED = 123\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.blackBox import BlackBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "black_box = BlackBox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('pickle\\\\data.pickle', 'rb') as f:\n",
    "    x_test, y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Unhinged follows the typical plot of the early 80\\'s slasher trend. Pretty Young Girls In Peril. I have to give it up for the filmmaker who used a helicopter for some of the early road-trip shots, you actually think for a second there\\'s going to be quality in the production. Watching \"Unhinged\" was like seeing an amateur acting class go through it\\'s warm-up. Some of the most awkward, badly lit, overlong scenes are played out with the gusto of a Valium overdose. I wondered why they didn\\'t just put the cue-cards on camera so the actresses wouldn\\'t have to constantly shift their gaze. The two main girls were obviously chosen for their T&A factor rather than talent. Laurel Munson as the main chick Terry is as exciting as watching paint dry. Two nude scenes make for an adolescent thrill. Janet Penner and Virginia Settle as the crazy/creepy daughter and mother the chicks find themselves stranded with compete for Worst Acting Ever. Long pauses, weird expressions, emphasis on the wrong word, it\\'s all there and is a delight for those of us out there who love bad films. The scenes shift suddenly with long black-outs you could drive a Mack truck through. Cartoon lightning crashes across shots without even bothering to show the sky. Eighties eyeshadow assaults the viewer. But ya know, it grew on me. I felt sorry for it. I wanted to hug it, kiss it\\'s boo-boos and make it better. The ending doesn\\'t make up for the damage it\\'s caused but I grinned anyway. I have my own theories regarding the whole \"banned\" hype and hope that anyone who chooses to view this film does so with substantial substance abuse and a sense of humor. Otherwise pass.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006194331\n"
     ]
    }
   ],
   "source": [
    "print(black_box.predict_sentiment(x_test[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perturb Algorythm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = list(zip(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Unhinged follows the typical plot of the early 80\\'s slasher trend. Pretty Young Girls In Peril. I have to give it up for the filmmaker who used a helicopter for some of the early road-trip shots, you actually think for a second there\\'s going to be quality in the production. Watching \"Unhinged\" was like seeing an amateur acting class go through it\\'s warm-up. Some of the most awkward, badly lit, overlong scenes are played out with the gusto of a Valium overdose. I wondered why they didn\\'t just put the cue-cards on camera so the actresses wouldn\\'t have to constantly shift their gaze. The two main girls were obviously chosen for their T&A factor rather than talent. Laurel Munson as the main chick Terry is as exciting as watching paint dry. Two nude scenes make for an adolescent thrill. Janet Penner and Virginia Settle as the crazy/creepy daughter and mother the chicks find themselves stranded with compete for Worst Acting Ever. Long pauses, weird expressions, emphasis on the wrong word, it\\'s all there and is a delight for those of us out there who love bad films. The scenes shift suddenly with long black-outs you could drive a Mack truck through. Cartoon lightning crashes across shots without even bothering to show the sky. Eighties eyeshadow assaults the viewer. But ya know, it grew on me. I felt sorry for it. I wanted to hug it, kiss it\\'s boo-boos and make it better. The ending doesn\\'t make up for the damage it\\'s caused but I grinned anyway. I have my own theories regarding the whole \"banned\" hype and hope that anyone who chooses to view this film does so with substantial substance abuse and a sense of humor. Otherwise pass.',\n",
       "  0),\n",
       " ('Wow. I saw this movie and \"Up\" on the same day within an hour of each other at different theaters. I saw \"Mr Bug\" first, and was then totally disappointed in \"Up\"\\'s follow-up. What a beautiful and touching film! Movies of the 1930s and 40s to us nowadays can be irking with their melodramatic acting and dialog, but as animation the same melodrama and groaning humor can be wonderful. And the soft \"organic\" lines of 30s drawing AND the music just puts you in a nice comfortable mood and you can enjoy the show with all its little characters: ladybugs, grasshoppers, bees, snails, stinkbugs, flies, mosquitoes, beetles, crickets, and more each with all their own cute little (but not overbearing) idiosyncrasies. The interaction with the human world, from nemesis (cigar smokers, high-heel wearers, innocent kick-the-can playing kids) to the kind-hearted, and to the unknown destroyers, is realistic and fascinating. You care for the bugs, AND Dick and Mary. The protagonist Hoppity is not some perfect superman who comes to \"set things right\" but a starry-eyed optimist who leads everyone down the garden path (literally!), and every time you think it\\'s going to end happily in 1930s style, along comes another roadblock...! I was on the edge of my seat much more than with \"Up.\" I walked out of the movie theater grinning and chuckling: something that hasn\\'t happened in a long long long long time!',\n",
       "  1),\n",
       " (\"I accept that most 50's horror aren't scary by today's standards, but what the hell is this? When you see a title like this you expect to see blood and a blood thirsty beast. Instead we get no blood at all and a beast who either wants to take over the world or live in peace on Earth....yeah which is what the people wanted.<br /><br />The overall story is fine with the astronaut coming back to life and being one with the beast....but the title really kills the movie. Night of the Beast would have made the fans more happy because there really isn't any blood to speak of.<br /><br />I like how the 50's movies had endings that left room for a sequel but wisely never made one. This movie isn't the worst i've ever seen but its almost up there.<br /><br />2 out of 10\",\n",
       "  0)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population[0][0]\n",
    "population[0][1]\n",
    "#a,b = zip(*population)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLOVE\n",
    "\n",
    "```\n",
    "@inproceedings{pennington2014glove,\n",
    "  author = {Jeffrey Pennington and Richard Socher and Christopher D. Manning},\n",
    "  booktitle = {Empirical Methods in Natural Language Processing (EMNLP)},\n",
    "  title = {GloVe: Global Vectors for Word Representation},\n",
    "  year = {2014},\n",
    "  pages = {1532--1543},\n",
    "  url = {http://www.aclweb.org/anthology/D14-1162},\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = {}\n",
    "\n",
    "with open(\"counter_fitted_word_vectors\\\\counter-fitted-vectors.txt\", \"r\",errors ='ignore', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype=\"float32\")\n",
    "        embeddings_dict[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.preprocessing import Preprocesser\n",
    "\n",
    "x_test = [Preprocesser.raw_text_preprocessing(sentence) for sentence in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76229\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "MAXLEN = 10_000 #60_000\n",
    "\n",
    "tokenizer = Tokenizer(MAXLEN)\n",
    "\n",
    "tokenizer.fit_on_texts(x_test)\n",
    "\n",
    "print(len(tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_dictionary = tokenizer.word_index\n",
    "\n",
    "inverse_tokens_dictionary = {v : k for (k, v) in tokenizer.word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 1), ('and', 2), ('a', 3)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokens_dictionary.items())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'the'), (2, 'and'), (3, 'a')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(inverse_tokens_dictionary.items())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('pickle\\\\tokens_dicts.pickle', 'wb') as f:\n",
    "    pickle.dump([tokens_dictionary,inverse_tokens_dictionary], f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros(shape = (MAXLEN+1, 300), dtype= 'float32')\n",
    "\n",
    "for w, i in tokenizer.word_index.items():\n",
    "    if w in embeddings_dict and i < MAXLEN+1:\n",
    "        embedding_matrix[i,:] = embeddings_dict[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs('numpy_files', exist_ok=True)\n",
    "np.save('numpy_files\\embedding_matrix.npy', embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.load('numpy_files\\embedding_matrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import normalize #minmax_scale\n",
    "\n",
    "#embedding_matrix = minmax_scale(embedding_matrix, feature_range=(0, 1), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(embeddings_dict['king'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
       "         0.      ],\n",
       "       [ 0.022847, -0.01317 , -0.025261, ..., -0.039248,  0.001481,\n",
       "         0.055489],\n",
       "       [ 0.012515, -0.019482, -0.005424, ..., -0.079507,  0.019481,\n",
       "        -0.01417 ],\n",
       "       ...,\n",
       "       [-0.001293, -0.011681, -0.02068 , ..., -0.013038, -0.032717,\n",
       "         0.10921 ],\n",
       "       [-0.051234, -0.010331, -0.043611, ..., -0.032198, -0.006921,\n",
       "        -0.025031],\n",
       "       [-0.033761, -0.095648, -0.071449, ...,  0.089715, -0.011441,\n",
       "         0.021954]], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nembedding_matrix = np.zeros((len(embeddings_dict), 300))\\n\\nfor w, emb in embeddings_dict.items():\\n    embedding_matrix[words_glove_dictionary[w],:] = emb\\n'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "embedding_matrix = np.zeros((len(embeddings_dict), 300))\n",
    "\n",
    "for w, emb in embeddings_dict.items():\n",
    "    embedding_matrix[words_glove_dictionary[w],:] = emb\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10001, 300)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "distance_matrix = cosine_distances(embedding_matrix, embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom scipy import spatial\\n\\ndef compute_euclidean_distance(X):\\n    V = spatial.distance.pdist(X.T, 'sqeuclidean')\\n    return spatial.distance.squareform(V)\\n\\ndistance_matrix = compute_euclidean_distance(embedding_matrix)\\n#distance_matrix = spatial.distance_matrix(embedding_matrix, embedding_matrix)\\n\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from scipy import spatial\n",
    "\n",
    "def compute_euclidean_distance(X):\n",
    "    V = spatial.distance.pdist(X.T, 'sqeuclidean')\n",
    "    return spatial.distance.squareform(V)\n",
    "\n",
    "distance_matrix = compute_euclidean_distance(embedding_matrix)\n",
    "#distance_matrix = spatial.distance_matrix(embedding_matrix, embedding_matrix)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 1.        , 1.        , ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       [1.        , 0.        , 0.6060601 , ..., 0.9962219 , 0.87981826,\n",
       "        1.0407182 ],\n",
       "       [1.        , 0.6060601 , 0.        , ..., 0.9895136 , 0.8719094 ,\n",
       "        0.8907523 ],\n",
       "       ...,\n",
       "       [1.        , 0.9962219 , 0.9895136 , ..., 0.        , 1.0547255 ,\n",
       "        0.926983  ],\n",
       "       [1.        , 0.87981826, 0.8719094 , ..., 1.0547255 , 0.        ,\n",
       "        0.83378804],\n",
       "       [1.        , 1.0407182 , 0.8907523 , ..., 0.926983  , 0.83378804,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs('numpy_files', exist_ok=True)\n",
    "np.save('numpy_files\\distance_matrix.npy', distance_matrix)\n",
    "\n",
    "#distance_matrix = np.load('numpy_files\\distance_matrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix = np.load('numpy_files\\distance_matrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_dictionary['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max(distance_matrix[:,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"with open('pickle\\\\distance_matrix.pickle', 'wb') as f:\\n    pickle.dump(distance_matrix, f)\\nf.close()\""
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''with open('pickle\\\\distance_matrix.pickle', 'wb') as f:\n",
    "    pickle.dump(distance_matrix, f)\n",
    "f.close()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distance_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from sklearn.preprocessing import normalize\\n\\nnormalized_distance_matrix = normalize(distance_matrix, axis = 1, norm = 'l1')\""
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.preprocessing import normalize\n",
    "\n",
    "normalized_distance_matrix = normalize(distance_matrix, axis = 1, norm = 'l1')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(word, delta = 0.5, num_words = 20):\n",
    "    \n",
    "    try:\n",
    "        index = tokens_dictionary[word]\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "    if (index > distance_matrix.shape[0]):\n",
    "        return []\n",
    "    \n",
    "    dist_order = np.argsort(distance_matrix[index,:])[1:num_words+1]\n",
    "    dist_list = distance_matrix[index][dist_order]\n",
    "    \n",
    "    mask = np.ones_like(dist_list)\n",
    "    mask = np.where(dist_list < delta)\n",
    "    return dist_order[mask]#, dist_list[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def most_similar(word, delta = 0.5, num_words = 20):\\n    \\n    try:\\n        index = tokenizer.word_index[word]\\n    except:\\n        return [], []\\n    \\n    if (index > distance_matrix.shape[0]):\\n        return [], []\\n    \\n    dist_order = np.argsort(distance_matrix[index,:])[1:num_words+1]\\n    dist_list = distance_matrix[index][dist_order]\\n    \\n    print(dist_order)\\n    print(dist_list)\\n    \\n    #return dist_order, dist_list\\n\\n    #if dist_list[-1] == 0:\\n    #    return [], []\\n    \\n    mask = np.ones_like(dist_list)\\n    #print(mask)\\n    mask = np.where(dist_list < delta)\\n    return dist_order[mask], dist_list[mask]'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def most_similar(word, delta = 0.5, num_words = 20):\n",
    "    \n",
    "    try:\n",
    "        index = tokenizer.word_index[word]\n",
    "    except:\n",
    "        return [], []\n",
    "    \n",
    "    if (index > distance_matrix.shape[0]):\n",
    "        return [], []\n",
    "    \n",
    "    dist_order = np.argsort(distance_matrix[index,:])[1:num_words+1]\n",
    "    dist_list = distance_matrix[index][dist_order]\n",
    "    \n",
    "    print(dist_order)\n",
    "    print(dist_list)\n",
    "    \n",
    "    #return dist_order, dist_list\n",
    "\n",
    "    #if dist_list[-1] == 0:\n",
    "    #    return [], []\n",
    "    \n",
    "    mask = np.ones_like(dist_list)\n",
    "    #print(mask)\n",
    "    mask = np.where(dist_list < delta)\n",
    "    return dist_order[mask], dist_list[mask]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = most_similar('fear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7706, 1650, 1829, 2581, 5315, 5009, 5396, 2409, 3356, 5998, 8992,\n",
       "       6061, 3680, 4962,  179, 4288,  679, 9200, 4037, 9026], dtype=int64)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fright',\n",
       " 'afraid',\n",
       " 'scared',\n",
       " 'scare',\n",
       " 'frightened',\n",
       " 'panic',\n",
       " 'angst',\n",
       " 'terror',\n",
       " 'worry',\n",
       " 'terrified',\n",
       " 'anxiety',\n",
       " 'dread',\n",
       " 'worried',\n",
       " 'bang',\n",
       " 'horror',\n",
       " 'concern',\n",
       " 'scary',\n",
       " 'feared',\n",
       " 'fears',\n",
       " 'worries']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[inverse_tokens_dictionary[index] for index in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ALTERNATIVE ###\n",
    "from scipy import spatial\n",
    "\n",
    "def find_nearest_neighbours(word, n = 20, delta = 0.5):\n",
    "    embedding = embeddings_dict[word]\n",
    "    return sorted(embeddings_dict.keys(), key=lambda w: spatial.distance.cosine(embeddings_dict[w], embedding))[1:20+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fright',\n",
       " 'afraid',\n",
       " 'scared',\n",
       " 'scare',\n",
       " 'frightened',\n",
       " 'panic',\n",
       " 'fearful',\n",
       " 'affraid',\n",
       " 'angst',\n",
       " 'terror',\n",
       " 'worry',\n",
       " 'terrified',\n",
       " 'freaked',\n",
       " 'spooked',\n",
       " 'anxiety',\n",
       " 'frighten',\n",
       " 'dread',\n",
       " 'trepidation',\n",
       " 'worried',\n",
       " 'apprehensive']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_nearest_neighbours('fear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU-1.13",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

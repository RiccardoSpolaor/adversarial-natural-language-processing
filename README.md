# :vs: Adversarial Natural Language Processing :newspaper: :pencil:
*Deep Neural Networks* can be compromised by attacks that lead them to wrong classification of instances which have been modified through small perturbations. These instances are called *Adversarial Examples*. In the *Natural Language Processing (NLP)* field, unlike other applications, a minimal perturbation of an instance can be evident to the human eye: editing a singular word in the corpus of a text can lead to variation or loss of its original meaning.

This thesis project follow the experiment of the paper [*Generating Natural Language Adversarial Examples*](https://aclanthology.org/D18-1316/) and proposes the use of a genetic optimization algorithm that generates Adversarial Examples which maintain a syntactic and semantic meaning similar to the one of the original text, while managing to trick a DNN *Sentiment Analysis* model.

## Versioning

Git is used for versioning.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
 


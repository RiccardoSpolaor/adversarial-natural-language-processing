{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.seed_setter import set_seed\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle,os\n",
    "\n",
    "with open(os.path.join('./pickle_data/train_test_data/test_data.pickle'), 'rb') as f:\n",
    "    x_test, y_test = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.black_box import BlackBox\n",
    "black_box = BlackBox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = black_box.predict_all(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_list = []\n",
    "\n",
    "attack_list = []\n",
    "\n",
    "for sent, lab, pred in list(zip(x_test, y_test, all_preds)):\n",
    "        if round(pred) == lab and len(sent) < 500:\n",
    "            attack_list += [(sent,lab)]\n",
    "        else:\n",
    "            adversarial_list += [(sent,lab)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(attack_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_list[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy for the attack list:')\n",
    "black_box.evaluate([sent for sent, lab in attack_list], [lab for sent, lab in attack_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy for the adversarial list:')\n",
    "black_box.evaluate([sent for sent, lab in adversarial_list], [lab for sent, lab in adversarial_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15140/15140 [==============================] - 38s 3ms/sample - loss: 0.0422 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.042179462103766135, 1.0]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(word, delta = 0.5, num_words = 20):\n",
    "    \n",
    "    try:\n",
    "        index = tokens_dictionary[word]\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "    if (index > distance_matrix.shape[0]):\n",
    "        return []\n",
    "    \n",
    "    dist_order = np.argsort(distance_matrix[index,:])[1:num_words+1]\n",
    "    dist_list = distance_matrix[index][dist_order]\n",
    "    \n",
    "    mask = np.ones_like(dist_list)\n",
    "    mask = np.where(dist_list < delta)\n",
    "    return [inverse_tokens_dictionary[index] for index in dist_order[mask]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "class Attack(object):\n",
    "    \n",
    "    def __init__ (self):\n",
    "        with open(os.path.join('./pickle_data/attack_utils/tokens_dictionary.pickle'), 'rb') as f:\n",
    "            tokens_dictionary, inverse_tokens_dictionary = pickle.load(f)\n",
    "            self.__tokens_dictionary = tokens_dictionary\n",
    "            self.__inverse_tokens_dictionary = inverse_tokens_dictionary\n",
    "        f.close()\n",
    "        \n",
    "        self.__black_box = BlackBox()\n",
    "        self.__distance_matrix = np.load(os.path.join('./numpy_files/distance_matrix.npy'))\n",
    "        self.__google_lm = google_language_model_utils.LM()\n",
    "        self.__stopwords = nltk.corpus.stopwords.words('english')\n",
    "        self.__sentence_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "        self.__tree_bank_word_tokenizer = TreebankWordTokenizer()\n",
    "        \n",
    "        latin_similar = \"’'‘ÆÐƎƏƐƔĲŊŒẞÞǷȜæðǝəɛɣĳŋœĸſßþƿȝĄƁÇĐƊĘĦĮƘŁØƠŞȘŢȚŦŲƯY̨Ƴąɓçđɗęħįƙłøơşșţțŧųưy̨ƴÁÀÂÄǍĂĀÃÅǺĄÆǼǢƁĆĊĈČÇĎḌĐƊÐÉÈĖÊËĚĔĒĘẸƎƏƐĠĜǦĞĢƔáàâäǎăāãåǻąæǽǣɓćċĉčçďḍđɗðéèėêëěĕēęẹǝəɛġĝǧğģɣĤḤĦIÍÌİÎÏǏĬĪĨĮỊĲĴĶƘĹĻŁĽĿʼNŃN̈ŇÑŅŊÓÒÔÖǑŎŌÕŐỌØǾƠŒĥḥħıíìiîïǐĭīĩįịĳĵķƙĸĺļłľŀŉńn̈ňñņŋóòôöǒŏōõőọøǿơœŔŘŖŚŜŠŞȘṢẞŤŢṬŦÞÚÙÛÜǓŬŪŨŰŮŲỤƯẂẀŴẄǷÝỲŶŸȲỸƳŹŻŽẒŕřŗſśŝšşșṣßťţṭŧþúùûüǔŭūũűůųụưẃẁŵẅƿýỳŷÿȳỹƴźżžẓ\"\n",
    "        safe_characters = string.ascii_letters + string.digits + latin_similar + ' '\n",
    "        safe_characters += \"'\"\n",
    "        self.__safe_characters = safe_characters\n",
    "        \n",
    "        self.__max_iters = 5\n",
    "        self.__max_tests = 5\n",
    "        \n",
    "        \n",
    "    def __handle_contractions(self, sentence):\n",
    "        text = self.__tree_bank_word_tokenizer.tokenize(sentence)\n",
    "        return ' '.join(sentence)\n",
    "    \n",
    "    def __preprocess_sentence(self, sentence):\n",
    "        for symbol not in self.__safe_characters:\n",
    "            sentence = sentence.replace(symbol, ' ' + symbol + ' ')\n",
    "            \n",
    "        sentence = self.__handle_contractions(self, sentence)\n",
    "        return sentence.split()\n",
    "    \n",
    "    def __split_review(self, review):\n",
    "        sentences = self.__sentence_tokenizer(review)\n",
    "        for index, sentence in enumerate(setences):\n",
    "            sentences[index] = self.__preprocess_sentence(sentence).split()\n",
    "        return sentences\n",
    "            \n",
    "            \n",
    "    def __most_similar(self, word, delta = 0.5, num_words = 20):\n",
    "        try:\n",
    "            index = tokens_dictionary[word]\n",
    "        except:\n",
    "            return []\n",
    "\n",
    "        if (index > distance_matrix.shape[0]):\n",
    "            return []\n",
    "\n",
    "        dist_order = np.argsort(distance_matrix[index,:])[1:num_words+1]\n",
    "        dist_list = distance_matrix[index][dist_order]\n",
    "\n",
    "        mask = np.ones_like(dist_list)\n",
    "        mask = np.where(dist_list < delta)\n",
    "        return [inverse_tokens_dictionary[index] for index in dist_order[mask]]         \n",
    "    \n",
    "    ###### TO BE REDONE BETTER TO ACTUALLY REFORM A SENTENCE#####\n",
    "    def __rejoin_review(self, sentences):\n",
    "        for i, sent in enumerate (sentences):\n",
    "            sentences[i] = ' '.join(sent)\n",
    "        return ' '.join(sentences)\n",
    "    \n",
    "    def __perturb(self, sentences, word_to_change, neighbours_dictionary, y_target):\n",
    "        prefix = ' '.join(sentences[word_to_change[0]][ : word_to_change[1]])\n",
    "        suffix = ' '.join(sentences[word_to_change[0]][word_to_change[1]+1 : -1])\n",
    "        lm_preds = self.__google_lm.get_words_probs(\n",
    "            prefix, \n",
    "            neighbours_dictionary[word_to_change][:self.__max_tests], \n",
    "            suffix\n",
    "        )\n",
    "        \n",
    "        score_list = []\n",
    "        for adv_w in np.argsort(lm_preds): \n",
    "            adv_sentences = sentences[:]\n",
    "            adv_splitted_text = sentences[word_to_change[0]]\n",
    "            adv_splitted_text[word_to_change[0]] = nearest_words[adv_w]\n",
    "            \n",
    "            adv_review = self.__rejoin_review(adv_sentences)\n",
    "            \n",
    "            score = self.__black_box.predict_sentiment(adv_review)\n",
    "            score_list += [(adv_splitted_text, score)]\n",
    "            \n",
    "        adv_sentences_sorted =  sorted(score_list, key=lambda x: x[1])    \n",
    "        \n",
    "        if y_target == 0:\n",
    "            final_adv_sentence = adv_sentences_sorted[0][0]\n",
    "        else:\n",
    "            final_adv_sentence = adv_sentences_sorted[-1][0]\n",
    "            \n",
    "        sentences[word_to_change[0]] = final_adv_sentence\n",
    "        \n",
    "        return sentences\n",
    "        \n",
    "        \n",
    "    def attack (self, x_orig, y_orig):\n",
    "        y_target = int(not y_orig)\n",
    "        sentences = self.__split_review(x_orig)\n",
    "        neighbours_dictionary = {}\n",
    "        \n",
    "        for sent_idx, sent in enumerate(sentences):\n",
    "            for word_idx, word in enumerate(sent):\n",
    "                neighbours_dictionary[(sent_idx, word_idx)] = self.__most_similar(word, delta = 0.5, num_words = 50)\n",
    "                \n",
    "        neighbours_length = {key: len(value) for key, value in neighbours_dictionary.items()}\n",
    "        \n",
    "        for key in neighbours_length.keys():\n",
    "            if sentences[key[0]][key[1]] in self.__stopwords:\n",
    "                neighbours_length[key] = 0\n",
    "                \n",
    "        length_sum = sum(neighbours_length.values)\n",
    "        \n",
    "        #maybe optimize it\n",
    "        neighbours_length = {key: value/length_sum for key, value in neighbours_length.items()}\n",
    "        \n",
    "        words_to_change = np.random.choice(neighbours_length.keys(), size = self.__max_iters, p = neighbours_length.values())\n",
    "        \n",
    "        for w in words_to_change:\n",
    "            sentences = perturb(sentences, w, neighbours_dictionary, y_target)\n",
    "            \n",
    "        return self.__rejoin_review(sentences)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk.data\n",
    "import nltk\n",
    "\n",
    "\n",
    "def attack(review, y_target):\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    sentence_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    sentences = sentence_tokenizer.tokenize(review)\n",
    "    \n",
    "    for sent_idx, sent in enumerate(sentences):\n",
    "        if sent_idx < 3:\n",
    "            splitted_text = sent.split()\n",
    "\n",
    "            for w_idx, w in enumerate(splitted_text):\n",
    "                if w_idx < 10:\n",
    "                    w = w.lower()\n",
    "                    pattern = r\"[\\w]+|[^\\s\\w]\"\n",
    "                    if len(re.findall(pattern, splitted_text[w_idx])) == 1 and w not in stopwords:\n",
    "                        nearest_indexes = most_similar(w)\n",
    "                        nearest_words = [inverse_tokens_dictionary[index] for index in nearest_indexes]\n",
    "                        if len(nearest_words):\n",
    "                            prefix = ' '.join(splitted_text[:w_idx])\n",
    "                            print('Prefix:\\n'+prefix)\n",
    "                            suffix = ' '.join(splitted_text[w_idx + 1:])\n",
    "                            print('Suffix:\\n'+suffix)\n",
    "                            lm_preds = google_language_model.get_words_probs(prefix, nearest_words, suffix)\n",
    "\n",
    "                            score_list = []\n",
    "                            for adv_w in np.argsort(lm_preds): \n",
    "                                adv_sentences = sentences[:]\n",
    "                                adv_splitted_text = splitted_text[:]\n",
    "                                adv_splitted_text[w_idx] = nearest_words[adv_w]\n",
    "                                adv_sentences[sent_idx] = ' '.join(adv_splitted_text)\n",
    "                                review_adv = ' '.join(adv_sentences)\n",
    "                                score = black_box.predict_sentiment(review_adv)\n",
    "                                score_list += [(adv_splitted_text, score)]\n",
    "                                \n",
    "                            adv_sentences_sorted =  sorted(score_list, key=lambda x: x[1])    \n",
    "                            if y_target == 0:\n",
    "                                splitted_text = adv_sentences_sorted[0][0]\n",
    "                            else:\n",
    "                                splitted_text = adv_sentences_sorted[-1][0]\n",
    "                            sentences[sent_idx] = ' '.join(splitted_text)\n",
    "    return ' '.join(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix:\n",
      "This\n",
      "Suffix:\n",
      "could cure sleep disorders, thats how bad it is.\n",
      "Prefix:\n",
      "This movies\n",
      "Suffix:\n",
      "cure sleep disorders, thats how bad it is.\n",
      "Prefix:\n",
      "This movies did\n",
      "Suffix:\n",
      "sleep disorders, thats how bad it is.\n",
      "Prefix:\n",
      "This movies did remedy\n",
      "Suffix:\n",
      "disorders, thats how bad it is.\n",
      "Prefix:\n",
      "This movies did remedy hibernate disorders,\n",
      "Suffix:\n",
      "how bad it is.\n",
      "Prefix:\n",
      "This movies did remedy hibernate disorders, wouldnt how\n",
      "Suffix:\n",
      "it is.\n",
      "Prefix:\n",
      "The\n",
      "Suffix:\n",
      "dragged, and the bad guy is not that scary.\n",
      "Prefix:\n",
      "The tales dragged, and the\n",
      "Suffix:\n",
      "guy is not that scary.\n",
      "Prefix:\n",
      "The tales dragged, and the amiss\n",
      "Suffix:\n",
      "is not that scary.\n",
      "Prefix:\n",
      "You will not\n",
      "Suffix:\n",
      "see this one on TBS reruns.\n",
      "Prefix:\n",
      "You will not still\n",
      "Suffix:\n",
      "this one on TBS reruns.\n",
      "Prefix:\n",
      "You will not still admire this\n",
      "Suffix:\n",
      "on TBS reruns.\n",
      "Generated adversarial sentence\n",
      "Prefix:\n",
      "The\n",
      "Suffix:\n",
      "get you to the movie, but the movie just wasn't worth my 8.50.. it has some good effects, but the storyline.. yech, i like tommy lee jones and will smith as actors, they have both done some good films, but i wish they hadn't added this one to their resume's.\n",
      "Prefix:\n",
      "The trailer\n",
      "Suffix:\n",
      "you to the movie, but the movie just wasn't worth my 8.50.. it has some good effects, but the storyline.. yech, i like tommy lee jones and will smith as actors, they have both done some good films, but i wish they hadn't added this one to their resume's.\n",
      "Prefix:\n",
      "The trailer obtains you to the movie, but the\n",
      "Suffix:\n",
      "just wasn't worth my 8.50.. it has some good effects, but the storyline.. yech, i like tommy lee jones and will smith as actors, they have both done some good films, but i wish they hadn't added this one to their resume's.\n",
      "Prefix:\n",
      "To be honest, the\n",
      "Suffix:\n",
      "is better..\n",
      "Generated adversarial sentence\n",
      "Prefix:\n",
      "The\n",
      "Suffix:\n",
      "of this movie is \"personality is more important than beauty\".\n",
      "Prefix:\n",
      "The voicemail of this\n",
      "Suffix:\n",
      "is \"personality is more important than beauty\".\n",
      "Prefix:\n",
      "The voicemail of this cinema is \"personality is more\n",
      "Suffix:\n",
      "than beauty\".\n",
      "Prefix:\n",
      "\n",
      "Suffix:\n",
      "Garofalo is supposed to be the \"ugly duckling\", but the funny thing is that she's not at all ugly (actually she's a lot more attractive than Uma Thurman, the friend who looks like a model).Now, would this movie work if the \"ugly duckling\" was really unattractive?\n",
      "Prefix:\n",
      "janeane Garofalo is\n",
      "Suffix:\n",
      "to be the \"ugly duckling\", but the funny thing is that she's not at all ugly (actually she's a lot more attractive than Uma Thurman, the friend who looks like a model).Now, would this movie work if the \"ugly duckling\" was really unattractive?\n",
      "Prefix:\n",
      "When will\n",
      "Suffix:\n",
      "stop with this hypocrisy?In my opinion, despite the message that it wants to convey, this movie is simply ridiculous.\n",
      "Prefix:\n",
      "When will celebs\n",
      "Suffix:\n",
      "with this hypocrisy?In my opinion, despite the message that it wants to convey, this movie is simply ridiculous.\n",
      "Prefix:\n",
      "When will celebs halt with this hypocrisy?In my opinion,\n",
      "Suffix:\n",
      "the message that it wants to convey, this movie is simply ridiculous.\n",
      "Generated adversarial sentence\n",
      "Prefix:\n",
      "\n",
      "Suffix:\n",
      "pile of drivel to date!\n",
      "Prefix:\n",
      "meanest\n",
      "Suffix:\n",
      "of drivel to date!\n",
      "Prefix:\n",
      "meanest heaps of\n",
      "Suffix:\n",
      "to date!\n",
      "Prefix:\n",
      "\n",
      "Suffix:\n",
      "involved with this production should be ashamed of themselves.\n",
      "Prefix:\n",
      "each\n",
      "Suffix:\n",
      "with this production should be ashamed of themselves.\n",
      "Prefix:\n",
      "each implicated with this\n",
      "Suffix:\n",
      "should be ashamed of themselves.\n",
      "Prefix:\n",
      "each implicated with this productive should be\n",
      "Suffix:\n",
      "of themselves.\n",
      "Prefix:\n",
      "Not\n",
      "Suffix:\n",
      "single element of the movie was anything slightly like an original idea.\n",
      "Prefix:\n",
      "Not eden\n",
      "Suffix:\n",
      "element of the movie was anything slightly like an original idea.\n",
      "Prefix:\n",
      "Not eden exclusive\n",
      "Suffix:\n",
      "of the movie was anything slightly like an original idea.\n",
      "Prefix:\n",
      "Not eden exclusive aspect of the\n",
      "Suffix:\n",
      "was anything slightly like an original idea.\n",
      "Prefix:\n",
      "Not eden exclusive aspect of the films was\n",
      "Suffix:\n",
      "slightly like an original idea.\n",
      "Prefix:\n",
      "Not eden exclusive aspect of the films was somethin\n",
      "Suffix:\n",
      "like an original idea.\n",
      "Generated adversarial sentence\n",
      "Prefix:\n",
      "I\n",
      "Suffix:\n",
      "that the movie was really good.\n",
      "Prefix:\n",
      "I thinks that the\n",
      "Suffix:\n",
      "was really good.\n",
      "Prefix:\n",
      "I thinks that the movies was\n",
      "Suffix:\n",
      "good.\n",
      "Prefix:\n",
      "Subject,\n",
      "Suffix:\n",
      "and Nusrat Fateh ALi Khan's music were marvellous.\n",
      "Prefix:\n",
      "Subject, behaving and Nusrat Fateh ALi Khan's\n",
      "Suffix:\n",
      "were marvellous.\n",
      "Prefix:\n",
      "\n",
      "Suffix:\n",
      "the director has succeeded in showing the status of women in rural areas and how they suffer at the hands of male-dominated culture, he has neglected Phoolan's character a bit and has focussed more on the violence faced by her.\n",
      "Prefix:\n",
      "albeit the\n",
      "Suffix:\n",
      "has succeeded in showing the status of women in rural areas and how they suffer at the hands of male-dominated culture, he has neglected Phoolan's character a bit and has focussed more on the violence faced by her.\n",
      "Prefix:\n",
      "albeit the rector has\n",
      "Suffix:\n",
      "in showing the status of women in rural areas and how they suffer at the hands of male-dominated culture, he has neglected Phoolan's character a bit and has focussed more on the violence faced by her.\n",
      "Prefix:\n",
      "albeit the rector has avail in\n",
      "Suffix:\n",
      "the status of women in rural areas and how they suffer at the hands of male-dominated culture, he has neglected Phoolan's character a bit and has focussed more on the violence faced by her.\n",
      "Prefix:\n",
      "albeit the rector has avail in displaying the\n",
      "Suffix:\n",
      "of women in rural areas and how they suffer at the hands of male-dominated culture, he has neglected Phoolan's character a bit and has focussed more on the violence faced by her.\n",
      "Generated adversarial sentence\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    x_orig = attack_list[i][0]\n",
    "    y_orig = attack_list[i][1]\n",
    "    \n",
    "    y_target = int(not y_orig)\n",
    "    \n",
    "    adversarial_list.append((attack(x_orig, y_target), y_orig))\n",
    "   \n",
    "    \n",
    "    \n",
    "    print('Generated adversarial sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wow. I observed this movie and \"Up\" on the same day within an hour of each other at different theaters. I saw \"Mr Bug\" first, and was then totally disappointed in \"Up\"\\'s follow-up. What a beautiful and touching film! Movies of the 1930s and 40s to us nowadays can be irking with their melodramatic acting and dialog, but as animation the same melodrama and groaning humor can be wonderful. And the soft \"organic\" lines of 30s drawing AND the music just puts you in a nice comfortable mood and you can enjoy the show with all its little characters: ladybugs, grasshoppers, bees, snails, stinkbugs, flies, mosquitoes, beetles, crickets, and more each with all their own cute little (but not overbearing) idiosyncrasies. The interaction with the human world, from nemesis (cigar smokers, high-heel wearers, innocent kick-the-can playing kids) to the kind-hearted, and to the unknown destroyers, is realistic and fascinating. You care for the bugs, AND Dick and Mary. The protagonist Hoppity is not some perfect superman who comes to \"set things right\" but a starry-eyed optimist who leads everyone down the garden path (literally! ), and every time you think it\\'s going to end happily in 1930s style, along comes another roadblock...! I was on the edge of my seat much more than with \"Up.\" I walked out of the movie theater grinning and chuckling: something that hasn\\'t happened in a long long long long time!'"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorted(score_list, key=lambda x: x[1])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds = google_language_model.get_words_probs('hey', ['how', 'kill', 'stupid'], 'are you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 0]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[i for i in np.argsort(preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.1748647e-04, 1.0273188e-05, 4.0947703e-05], dtype=float32)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This movies did remedy hibernate disorders, wouldnt how naughty it is. The tales dragged, and the amiss fella is not that scary. You will not still admire this uno on TBS reruns. This film made me wonder about Chuck film choices. He work on a real dog with this one.',\n",
       "  0),\n",
       " (\"The trailer obtains you to the movie, but the cinema just wasn't worth my 8.50.. it has some good effects, but the storyline.. yech, i like tommy lee jones and will smith as actors, they have both done some good films, but i wish they hadn't added this one to their resume's. To be honest, the ledger is better..\",\n",
       "  0),\n",
       " ('The voicemail of this cinema is \"personality is more pivotal than beauty\". janeane Garofalo is hypothetical to be the \"ugly duckling\", but the funny thing is that she\\'s not at all ugly (actually she\\'s a lot more attractive than Uma Thurman, the friend who looks like a model).Now, would this movie work if the \"ugly duckling\" was really unattractive? When will celebs halt with this hypocrisy?In my opinion, albeit the message that it wants to convey, this movie is simply ridiculous.',\n",
       "  0),\n",
       " ('meanest heaps of quirk to date! each implicated with this productive should be embarassed of themselves. Not eden exclusive aspect of the films was somethin modestly like an original idea. A first grader telling you a story about nap time is more entertaining.',\n",
       "  0),\n",
       " (\"I thinks that the movies was truthfully good. Subject, behaving and Nusrat Fateh ALi Khan's musicians were marvellous. albeit the rector has avail in displaying the statute of women in rural areas and how they suffer at the hands of male-dominated culture, he has neglected Phoolan's character a bit and has focussed more on the violence faced by her.\",\n",
       "  1)]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adversarial_list[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This film could cure sleep disorders, thats how bad it is. The story dragged, and the bad guy is not that scary. You will not even see this one on TBS reruns. This film made me wonder about Chuck film choices. He work on a real dog with this one.',\n",
       "  0),\n",
       " (\"The trailers get you to the movie, but the movie just wasn't worth my 8.50.. it has some good effects, but the storyline.. yech, i like tommy lee jones and will smith as actors, they have both done some good films, but i wish they hadn't added this one to their resume's. To be honest, the book is better..\",\n",
       "  0),\n",
       " ('The message of this movie is \"personality is more important than beauty\". Jeanine Garofalo is supposed to be the \"ugly duckling\", but the funny thing is that she\\'s not at all ugly (actually she\\'s a lot more attractive than Uma Thurman, the friend who looks like a model).Now, would this movie work if the \"ugly duckling\" was really unattractive? When will Hollywood stop with this hypocrisy?In my opinion, despite the message that it wants to convey, this movie is simply ridiculous.',\n",
       "  0),\n",
       " ('Worst pile of drivel to date! Everyone involved with this production should be ashamed of themselves. Not one single element of the movie was anything slightly like an original idea. A first grader telling you a story about nap time is more entertaining.',\n",
       "  0),\n",
       " (\"I think that the movie was really good. Subject, acting and Nusrat Fateh ALi Khan's music were marvellous. Although the director has succeeded in showing the status of women in rural areas and how they suffer at the hands of male-dominated culture, he has neglected Phoolan's character a bit and has focussed more on the violence faced by her.\",\n",
       "  1)]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attack_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8820844292640686,\n",
       " 0.22996748983860016,\n",
       " 0.0038647179026156664,\n",
       " 0.7400735020637512,\n",
       " 0.39983099699020386]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "black_box.predict_all([sent for sent, lab in adversarial_list[-5:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "5/5 [==============================] - 0s 17ms/sample - loss: 0.9334 - acc: 0.4000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9334100484848022, 0.4]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "black_box.evaluate([sent for sent, lab in adversarial_list[-5:]], [lab for sent, lab in adversarial_list[-5:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "5/5 [==============================] - 0s 30ms/sample - loss: 0.0490 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04902750998735428, 1.0]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "black_box.evaluate([sent for sent, lab in attack_list[:5]], [lab for sent, lab in attack_list[:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU-1.13",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
